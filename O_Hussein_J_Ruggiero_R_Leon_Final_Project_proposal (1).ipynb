{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Video Game Relative to Demographics\n",
    "## Analytics Programming Final Project Proposal\n",
    "### Group members:\n",
    "- Omar M. Hussein\n",
    "- Julian Ruggiero\n",
    "- Randy Leon\n",
    "\n",
    "<img src=\"deathstr.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Introduction\n",
    "\n",
    "The video game industry has been perennially pushing the boundaries of what is attainable for digital entertainment. Contributions such as cloud gaming, Google Stadia, and increased mobile gaming capabilities has given video games the possibility to become a 300 billion dollar industry by 2025. [1]. In fact, both retro and modern video games now command the cultural influence that was once reserved for other areas in the entertainment industry such as movies and TV-shows. We are currently on the verge of a new age where video games are more prevalent than ever, and they are only on pace to continue growing in popularity. To put it into perspective, Rockstar's 'GTA V' is the most profitable entertainment product in history, overshadowing any other medium by a staggering 6 billion dollars in revenue since its release. [2].\n",
    "\n",
    "\"Death Stranding\" [3] is a forthcoming action game designed, written, produced, and directed by Hideo Kojima, one of the world's most highly regarded video game producers. His very first independent game was released on November 8th, 2019. There has been plenty of buzz regarding this game in the media, and we want to understand how people are reacting, while also, analyzing what Twitter users have to say about it. In this project, we endeavor to think strategically about how we could market to the global audience, or gamers on the state level, through text Sentiment Analysis based on a social media such as Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Research Questions\n",
    "\n",
    "A huge amount of money has been spent towards this game considering some of the actors involved. Mads Mikkelsen, Troy Baker and Norman Reedus [4] alone have given this game a hefty budget, let alone the money paid in development and in all other areas of production. These high-cost production factors are an indicator that this game has what it takes to be commercially successful.\n",
    "\n",
    "### Questions that we should take into account:\n",
    "- How do people feel about the product and what do they say?\n",
    "- Where should Sony's marketing focus be in the world?\n",
    "- What is the percentage breakdown of positive and negative comments over the different regions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 First data source\n",
    "The first data source is going to be a dataset called sentiment140. [5]. It contains 1,600,000 tweets extracted using the twitter API. The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment.\n",
    "\n",
    "Inside we can find the following 6 fields:\n",
    "\n",
    "- Target: The polarity of the tweet. (0 = negative, 4 = positive)\n",
    "- Ids: The ID of the tweet. (2087)\n",
    "- Date: The date of the tweet. (Sat, May 16 23:58:44 UTC 2009)\n",
    "- Flag: The query. (lyx). If there is no query, then this value is NO_QUERY.\n",
    "- User: The user that tweeted. (robotickilldozr)\n",
    "- Text: The text of the tweet. (Lyx is cool)\n",
    "\n",
    "Both, the official link regarding the dataset with resources about how it was generated and the official paper from Standford University students detailing the approach are in the citations below. [6] [7].\n",
    "\n",
    "\n",
    "## 3.2 Second data source\n",
    "The second data source will come directly from Twitter, more specifically, the tweets related to the Sony video game \"Death Stranding\". We will throw API requests and the text data collected will be stored in a database (the approach is explained in the next section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: Machine learning algorithm Description\n",
    "\n",
    "#### 4.1.1 Train/Test split\n",
    "\n",
    "<img src=\"TDS.png\" /> \n",
    "We are going to take the sentiment140 dataset from Kaggle which was created by Stanford University and then we are going to split the tweets dataset into two groups, training and test, with most of the data being allocated towards the training dataset to perform evaluation on our algorithm throughout implementation process.\n",
    "\n",
    "#####  4.1.2 The training data.\n",
    "\n",
    "The training data contains labelled outputs for each of the tweets and will be fed into a machine learning algorithm (like Naive Bayes or support vector machine) which will produce a tweet classifier, which by now should have developed a hypothesis of what the differences between a bad tweet and a good tweet is.\n",
    "\n",
    "<img src=\"valstar.PNG\" /> - Credits go to Dr.M.Valstar for the figure above (Professor at the University of Nottingham, UK).\n",
    "\n",
    "Notation:\n",
    "- x: training dataset.\n",
    "- h: hypothesis (in this case a classifier).\n",
    "- y: output (in this case predicted output).\n",
    "\n",
    "#####  4.1.3 The test data.\n",
    "\n",
    "The test data is going to be used to help in the evaluation of the accuracy and precision of our model as it is still far from impervious to malperformance and it is still susceptible to overfitting [8] and underfitting [9]. In order to circumvent this problem we must ensure that the model generalizes well on unseen data [10] through an iterative process of fine tuning the model until it performs well on both the training set and the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Death Stranding dataset\n",
    "\n",
    "### 4.2.1  Death Stranding tweets.\n",
    "\n",
    "<img src=\"hideo1.jpg\" />\n",
    "\n",
    "We will get tweets about the game \"Death Stranding\", like the example above, and perform requests to the social network Twitter using its API to collect tweets. We plan to store the tweets and some other attributes such as its location in a database. To be able to perform this we will create a Twitter developer account and use a Python library called TweePy alongside some other secondary libraries, then obtain the corresponding keys and tokens to interact with the API to get the data.\n",
    "\n",
    "The API has some limitations in the number of requests every 15 minutes, so we will perform this operation incrementally as time passes by, as we plan to understand how people react to \"Death Stranding\" in the hopes of answering our research questions and the way we intend to do this is through classifying the tweets into positive and negative in relation to their geographical location. For the tweets that don't have a geographical location, they will be considered separately to have a comprehensive idea of the video game market's sentiment towards our product.\n",
    "\n",
    "However, since the release date was on November 8, 2019 it is imperative to get more tweets around that time because we would like to know what type of improvements hideo kojima needs to make in order to generate more revenue.\n",
    "\n",
    "### 4.2.2. Pre-processing.\n",
    "After storing the death stranding tweets in the database and before we use our machine learning classifier we first have to ensure that the data is clean and since this is a text based data we have devised a curation list of all the possible aspects that need pre-processing, which includes converting more than two letter repetitions into two letter, exclude non-valid words, dealing with URLs and handling emojis, among others.\n",
    "\n",
    "### 4.2.3. Database management\n",
    "In the hopes of making our project accessible to the team and more reproducible to the interested parties we are going to use MongoDB in the cloud. MongoDBâ€™s document model is a simple cross-platform for developers to learn and use, while still providing all the capabilities needed to meet the most complex requirements at any scale. [11].\n",
    "\n",
    "\n",
    "## 5: Conclusions and Visualization\n",
    "\n",
    "The final result would include the construction of a choropleth map that will show positive and negative tweets distribution and variations between countries, and if possible at a state level and deriving conclusion that could help us answer our research questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. References\n",
    "\n",
    "[1] https://variety.com/2019/gaming/news/video-games-300-billion-industry-2025-report-1203202672/\n",
    "\n",
    "[2] https://www.marketwatch.com/story/this-violent-videogame-has-made-more-money-than-any-movie-ever-2018-04-06\n",
    "\n",
    "[3] https://www.playstation.com/en-us/games/death-stranding-ps4/\n",
    "\n",
    "[4] https://en.wikipedia.org/wiki/Death_Stranding\n",
    "\n",
    "[5] https://www.kaggle.com/kazanova/sentiment140\n",
    "\n",
    "[6] http://help.sentiment140.com/for-students\n",
    "\n",
    "[7] https://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf\n",
    "\n",
    "[8] https://www.investopedia.com/terms/o/overfitting.asp\n",
    "\n",
    "[9] https://www.datarobot.com/wiki/underfitting/\n",
    "\n",
    "[10] https://developers.google.com/machine-learning/crash-course/generalization/video-lecture\n",
    "\n",
    "[11] https://www.mongodb.com/what-is-mongodb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
